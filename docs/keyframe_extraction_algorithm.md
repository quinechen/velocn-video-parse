# 关键帧提取算法说明

## 算法概述

当前的关键帧提取算法采用**两阶段方法**：
1. **场景检测阶段**：识别视频中的场景切换点
2. **关键帧提取阶段**：在每个场景中提取代表性关键帧

## 详细流程

### 阶段一：视频帧采样提取

#### 1.1 帧采样策略（使用 Seek 优化）

**目标**：高效提取用于分析的视频帧，避免处理整个视频

**算法**：
```
1. 根据采样率计算需要提取的时间点
   - 采样率：默认 2.0 fps，可通过 --sample-rate 参数调整
   - 时间间隔 = 1.0 / 采样率（秒）
   - 例如：采样率 20.0 fps → 每 0.05 秒提取一帧

2. 对每个时间点执行：
   a. 使用 av_seek_frame() 跳转到目标时间点（向后查找最近的 keyframe）
   b. 刷新解码器缓冲区
   c. 读取并解码帧，找到最接近目标时间的帧
   d. 将帧转换为 RGB24 格式并保存
```

**优势**：
- 处理时间不再与视频时长成正比
- 只解码需要的帧，跳过大量中间帧
- 对于 48 秒视频，采样率 20 fps：只需处理约 960 帧，而不是全部 1440 帧

**代码位置**：`video-parse/src/video_processor.rs::extract_frames()`

### 阶段二：场景检测（高级算法）

#### 2.1 多维度帧差异计算

**目标**：使用多种方法量化两帧之间的视觉差异，特别针对高级转场特效（如主体不变但背景变化）

**算法**：采用**5种方法组合**，加权计算最终差异度

```
对于相邻两帧 frame1 和 frame2：

1. 区域分割分析（权重 25%）
   - 将图像分成中心区域（30%-70%，主体）和边缘区域（背景）
   - 分别计算两个区域的差异
   - 如果边缘区域变化大但中心区域变化小，说明可能是背景变化
   - 对背景变化给予更高的差异分数
   - 优势：能检测"主体不变但背景变化"的情况

2. 边缘检测差异（权重 25%）
   - 使用Sobel算子检测边缘
   - 计算边缘强度分布
   - 比较两帧的边缘信息变化
   - 优势：边缘变化更能反映场景切换，对渐变转场敏感

3. HSV颜色空间分析（权重 20%）
   - 将RGB转换为HSV颜色空间
   - 比较色调（Hue）和饱和度（Saturation）的变化
   - 对背景颜色变化敏感
   - 优势：能检测颜色渐变和背景色调变化

4. 梯度分析（权重 15%）
   - 计算图像梯度（使用差分算子）
   - 比较梯度分布的变化
   - 优势：捕捉图像结构变化

5. 传统方法（权重 15%）
   - 直方图差异（60%）+ 像素差异（40%）
   - 作为基础参考

最终差异 = 区域差异 × 0.25 + 边缘差异 × 0.25 + HSV差异 × 0.20 + 梯度差异 × 0.15 + 传统差异 × 0.15
```

**特点**：
- **区域分割**：区分主体和背景，检测背景变化
- **边缘检测**：捕捉结构变化，对渐变转场敏感
- **HSV分析**：检测颜色空间变化，对色调变化敏感
- **梯度分析**：捕捉图像结构变化
- **多维度组合**：综合多种方法，提高检测准确性

**适用场景**：
- ✅ 主体不变但背景变化的转场
- ✅ 渐变转场特效
- ✅ 颜色渐变
- ✅ 复杂的视觉效果
- ✅ 传统场景切换

**代码位置**：`video-parse/src/scene_detector.rs::calculate_frame_difference()`

#### 2.2 场景切换检测

**目标**：识别视频中的场景切换点

**算法**：
```
输入：提取的帧序列 frames = [(时间戳, 图像), ...]
参数：
  - threshold: 场景变化阈值（默认 0.3）
  - min_scene_duration: 最小场景持续时间（默认 1.0 秒）

流程：
1. 初始化场景列表 scene_changes = [0.0]（第一个场景从 0 开始）

2. 遍历帧序列（从第 2 帧开始）：
   for i in 1..frames.len():
     a. 计算 frames[i-1] 和 frames[i] 的差异度 diff
     b. 如果 diff > threshold：
        - 检查距离上次场景切换的时间间隔
        - 如果 time_since_last >= min_scene_duration：
            * 记录场景切换点：scene_changes.push(frames[i].时间戳)
```

**参数说明**：
- `threshold`（默认 0.3）：
  - 值越大：检测越敏感，更容易检测到场景变化
  - 值越小：检测越保守，只检测明显的场景变化
  - 范围：0.0 - 1.0

- `min_scene_duration`（默认 1.0 秒）：
  - 防止过于频繁的场景切换检测
  - 确保每个场景至少持续指定时间

**代码位置**：`video-parse/src/scene_detector.rs::detect_scenes()`

### 阶段三：关键帧提取

#### 3.1 关键帧数量策略

**目标**：每个场景只提取 1 个最具代表性的关键帧

**设计理念**：
- **避免重复**：长场景中固定间隔提取会产生大量相似的关键帧
- **选择中间区域**：场景开始和结束通常包含过渡内容，中间区域更能代表场景主体
- **选择稳定帧**：在中间区域选择最稳定的帧（与相邻帧差异最小），避免选择运动剧烈的帧

#### 3.2 关键帧位置选择（智能算法）

**目标**：在场景中间区域选择最稳定的帧作为关键帧

**算法**：
```
对于每个场景：
  1. 确定场景中间区域：30% - 70% 位置
     - scene_mid_start = scene_start + duration × 0.3
     - scene_mid_end = scene_start + duration × 0.7
  
  2. 找到中间区域内的所有帧
  
  3. 如果中间区域有多个帧：
     a. 对每个候选帧，计算与前后帧的平均差异
     b. 选择差异最小的帧（最稳定的帧）
  
  4. 如果中间区域没有帧或只有1个帧：
     - 选择场景中间位置（50%）的帧
```

**优势**：
- **避免过渡帧**：不选择场景开始和结束的过渡帧
- **选择稳定帧**：优先选择画面稳定的帧，更能代表场景主体
- **减少重复**：每个场景只提取1个关键帧，避免内容重复

#### 3.3 稳定性计算

**目标**：量化帧的稳定性（与相邻帧的相似度）

**算法**：
```
对于候选帧 frame[i]：

1. 计算与前一个帧的差异：
   diff_prev = calculate_frame_difference(frame[i-1], frame[i])
   
2. 计算与后一个帧的差异：
   diff_next = calculate_frame_difference(frame[i], frame[i+1])
   
3. 计算平均差异：
   avg_diff = (diff_prev + diff_next) / 2
   
4. 选择 avg_diff 最小的帧作为关键帧
```

**特点**：
- 差异越小，帧越稳定
- 稳定的帧通常包含场景的主要内容，而不是运动或过渡

**代码位置**：`video-parse/src/processor.rs::process_video()` (第 78-147 行)

## 算法参数

### 可配置参数

| 参数 | 默认值 | 说明 | 影响 |
|------|--------|------|------|
| `--sample-rate` | 2.0 fps | 帧采样率 | 影响场景检测精度和处理速度 |
| `--threshold` | 0.3 | 场景变化阈值 | 影响场景检测的敏感度 |
| `--min-scene-duration` | 1.0 秒 | 最小场景持续时间 | 防止过度细分场景 |

### 固定参数

| 参数 | 值 | 说明 |
|------|-----|------|
| 中间区域范围 | 30% - 70% | 关键帧候选区域（场景中间区域） |

## 算法示例

### 示例：48 秒视频，采样率 20 fps

**阶段一：帧提取**
- 时间间隔：1.0 / 20.0 = 0.05 秒
- 提取帧数：48 / 0.05 ≈ 960 帧
- 使用 seek 优化，实际处理时间：约 40 秒（而不是 48 秒）

**阶段二：场景检测**
- 检测到 14 个场景
- 场景时长分布：1.0 秒 - 8.8 秒

**阶段三：关键帧提取**
- 场景 0（1.0秒）：1 个关键帧（中间区域最稳定帧）
- 场景 1（6.0秒）：1 个关键帧（中间区域最稳定帧）
- 场景 3（8.8秒）：1 个关键帧（中间区域最稳定帧）
- ...
- 总计：14 个关键帧（每个场景1个）

## 算法优势

1. **高效性**：
   - 使用 seek 跳转，避免处理整个视频
   - 只解码需要的帧
   - 每个场景只提取1个关键帧，减少冗余
   - 多维度分析虽然计算量增加，但通过采样和优化保持合理性能

2. **准确性**：
   - **多维度检测**：结合5种不同的差异度量方法，提高场景检测准确性
   - **高级转场支持**：能检测主体不变但背景变化的情况
   - **渐变转场检测**：边缘检测和HSV分析对渐变转场敏感
   - 选择场景中间区域，避免过渡帧
   - 选择最稳定的帧，更能代表场景主体

3. **灵活性**：
   - 可配置采样率和阈值
   - 智能选择关键帧位置，而非固定间隔
   - 多种检测方法组合，适应不同类型的视频内容

4. **鲁棒性**：
   - 最小场景持续时间防止过度细分
   - 稳定性计算确保选择最具代表性的帧
   - 避免选择场景开始和结束的过渡帧
   - 区域分割分析减少主体运动对检测的影响

## 算法局限性

1. **场景检测依赖阈值**：
   - 阈值设置不当可能导致场景检测不准确
   - 渐变场景可能被误判为单个场景

2. **关键帧选择策略**：
   - 当前选择最稳定的帧，可能不适合需要捕捉运动的内容
   - 对于快速变化的场景，中间区域可能不是最佳选择

3. **帧采样率影响**：
   - 采样率过低可能遗漏快速场景切换
   - 采样率过高会增加处理时间
   - 采样率影响中间区域帧的数量，进而影响稳定性计算

## 改进建议

1. **自适应阈值**：根据视频内容动态调整阈值
2. **内容感知关键帧**：基于视觉重要性选择关键帧（如人脸检测、物体识别）
3. **多尺度检测**：结合不同时间尺度的场景检测
4. **关键帧质量评估**：结合清晰度、对比度等指标选择关键帧
5. **运动感知**：对于运动场景，可以选择运动最剧烈的帧而非最稳定的帧
6. **可配置策略**：允许用户选择"稳定帧"或"代表性帧"策略

