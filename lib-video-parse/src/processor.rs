use anyhow::{Context, Result};
use std::path::{Path, PathBuf};
use std::time::Instant;
use image::DynamicImage;
use crate::{VideoProcessor, SceneDetector, AudioExtractor, metadata::VideoMetadata};

/// è§†é¢‘å¤„ç†é…ç½®
#[derive(Debug, Clone)]
pub struct ProcessConfig {
    /// åœºæ™¯å˜åŒ–æ£€æµ‹é˜ˆå€¼
    pub threshold: f64,
    /// æœ€å°åœºæ™¯æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    pub min_scene_duration: f64,
    /// å¸§é‡‡æ ·ç‡ï¼ˆæ¯ç§’é‡‡æ ·å¤šå°‘å¸§ï¼‰
    pub sample_rate: f64,
    /// Webhook URLï¼ˆå¤„ç†å®Œæˆåå›è°ƒï¼‰
    pub webhook_url: Option<String>,
}

impl ProcessConfig {
    /// ä»ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶åŠ è½½é…ç½®
    pub fn from_env_and_file(config_file: Option<&std::path::Path>) -> anyhow::Result<Self> {
        use crate::config::ConfigLoader;
        ConfigLoader::load_config(config_file, None, None, None, None)
    }
}

impl Default for ProcessConfig {
    fn default() -> Self {
        Self {
            threshold: 0.35,
            min_scene_duration: 0.8,
            sample_rate: 0.5,
            webhook_url: None,
        }
    }
}

/// å¤„ç†ç»“æœ
#[derive(Debug, Clone)]
pub struct ProcessOutput {
    /// è¾“å‡ºç›®å½•
    pub output_dir: PathBuf,
    /// å…ƒæ•°æ®
    pub metadata: VideoMetadata,
    /// å…³é”®å¸§æ–‡ä»¶åˆ—è¡¨
    pub keyframe_files: Vec<String>,
    /// éŸ³é¢‘æ–‡ä»¶
    pub audio_file: String,
}

/// å¤„ç†è§†é¢‘æ–‡ä»¶
pub async fn process_video(
    input_video_path: impl AsRef<Path>,
    output_dir: impl AsRef<Path>,
    config: ProcessConfig,
) -> Result<ProcessOutput> {
    let input_video_path = input_video_path.as_ref();
    let output_dir = output_dir.as_ref();

    let total_start = Instant::now();
    println!("å¼€å§‹å¤„ç†è§†é¢‘: {}", input_video_path.display());
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    
    // åˆ›å»ºè¾“å‡ºç›®å½•
    let dir_start = Instant::now();
    std::fs::create_dir_all(output_dir)
        .context("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥")?;
    println!("[{}ms] âœ“ åˆ›å»ºè¾“å‡ºç›®å½•", dir_start.elapsed().as_millis());

    // 1. åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨
    let init_start = Instant::now();
    let processor = VideoProcessor::new(input_video_path)?;
    println!("[{}ms] âœ“ åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨", init_start.elapsed().as_millis());
    
    // 2. è·å–è§†é¢‘ä¿¡æ¯
    let info_start = Instant::now();
    let (fps, width, height) = processor.get_video_info()?;
    println!("[{}ms] âœ“ è·å–è§†é¢‘ä¿¡æ¯: {}x{}, {:.2} fps", 
        info_start.elapsed().as_millis(), width, height, fps);

    // 3. æå–è§†é¢‘å¸§
    let extract_start = Instant::now();
    println!("â³ æ­£åœ¨æå–è§†é¢‘å¸§ï¼ˆé‡‡æ ·ç‡: {:.1} fpsï¼‰...", config.sample_rate);
    let frames = processor.extract_frames(Some(config.sample_rate))?;
    let extract_duration = extract_start.elapsed();
    println!("[{}ms] âœ“ æå–è§†é¢‘å¸§å®Œæˆ: {} å¸§ (å¹³å‡ {:.2}ms/å¸§)", 
        extract_duration.as_millis(), 
        frames.len(),
        if frames.len() > 0 { extract_duration.as_millis() as f64 / frames.len() as f64 } else { 0.0 });

    // 4. æ£€æµ‹åœºæ™¯å˜åŒ–
    let scene_start = Instant::now();
    println!("â³ æ­£åœ¨æ£€æµ‹åœºæ™¯å˜åŒ–...");
    let detector = SceneDetector::new(config.threshold, config.min_scene_duration);
    let scene_changes = detector.detect_scenes(&frames, fps)?;
    let scene_duration = scene_start.elapsed();
    println!("[{}ms] âœ“ åœºæ™¯æ£€æµ‹å®Œæˆ: {} ä¸ªåœºæ™¯ (å¹³å‡ {:.2}ms/åœºæ™¯)", 
        scene_duration.as_millis(),
        scene_changes.len(),
        if scene_changes.len() > 0 { scene_duration.as_millis() as f64 / scene_changes.len() as f64 } else { 0.0 });

    // 5. æå–å…³é”®å¸§å¹¶ä¿å­˜
    let keyframe_start = Instant::now();
    println!("â³ æ­£åœ¨æå–å¹¶ä¿å­˜å…³é”®å¸§...");
    let mut scenes_metadata = Vec::new();
    let mut keyframe_files = Vec::new();
    let total_duration = frames.last().map(|(t, _)| *t).unwrap_or(0.0);
    
    // æ£€æŸ¥æ˜¯å¦æœ‰æå–çš„å¸§
    if frames.is_empty() {
        anyhow::bail!("æ²¡æœ‰æå–åˆ°ä»»ä½•è§†é¢‘å¸§ï¼Œæ— æ³•æå–å…³é”®å¸§");
    }
    
    // åˆ›å»ºåœºæ™¯æ£€æµ‹å™¨ç”¨äºè®¡ç®—å¸§å·®å¼‚
    let detector = SceneDetector::new(config.threshold, config.min_scene_duration);
    let mut keyframe_counter = 0;
    
    for (i, &scene_start) in scene_changes.iter().enumerate() {
        // ç¡®å®šåœºæ™¯ç»“æŸæ—¶é—´
        let scene_end = if i + 1 < scene_changes.len() {
            scene_changes[i + 1]
        } else {
            total_duration
        };
        
        let duration = scene_end - scene_start;
        
        // æ‰¾åˆ°å±äºå½“å‰åœºæ™¯çš„æ‰€æœ‰å¸§
        let scene_frames: Vec<(usize, &(f64, DynamicImage))> = frames.iter()
            .enumerate()
            .filter(|(_, (t, _))| *t >= scene_start && *t < scene_end)
            .collect();
        
        if scene_frames.is_empty() {
            // å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¸§ï¼Œä½¿ç”¨åœºæ™¯å¼€å§‹æ—¶é—´é™„è¿‘çš„å¸§
            let fallback_idx = frames.iter()
                .enumerate()
                .min_by(|(_, (t1, _)), (_, (t2, _))| {
                    ((*t1 - scene_start).abs()).partial_cmp(&((*t2 - scene_start).abs())).unwrap()
                })
                .map(|(idx, _)| idx);
            
            // å¦‚æœæ‰¾ä¸åˆ°å›é€€å¸§ï¼Œè·³è¿‡è¿™ä¸ªåœºæ™¯
            let fallback_idx = match fallback_idx {
                Some(idx) => idx,
                None => {
                    println!("âš ï¸  åœºæ™¯ {}: æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å¸§ï¼Œè·³è¿‡", i);
                    continue;
                }
            };
            
            let (_keyframe_time, keyframe_img) = &frames[fallback_idx];
            let keyframe_filename = format!("keyframe_{:04}.jpg", keyframe_counter);
            let keyframe_path = output_dir.join(&keyframe_filename);
            keyframe_img.save(&keyframe_path)
                .context(format!("ä¿å­˜å…³é”®å¸§å¤±è´¥: {}", keyframe_filename))?;
            
            keyframe_files.push(keyframe_filename.clone());
            scenes_metadata.push(crate::metadata::SceneMetadata {
                scene_id: i,
                keyframe_file: keyframe_filename,
                start_time: scene_start,
                end_time: scene_end,
                duration,
            });
            keyframe_counter += 1;
            continue;
        }
        
        // æ¯ä¸ªåœºæ™¯åªæå–1ä¸ªå…³é”®å¸§
        // ç­–ç•¥ï¼šåœ¨åœºæ™¯ä¸­é—´åŒºåŸŸï¼ˆ30%-70%ï¼‰é€‰æ‹©æœ€ç¨³å®šçš„å¸§ï¼ˆä¸ç›¸é‚»å¸§å·®å¼‚æœ€å°ï¼‰
        let scene_mid_start = scene_start + duration * 0.3;
        let scene_mid_end = scene_start + duration * 0.7;
        
        // æ‰¾åˆ°ä¸­é—´åŒºåŸŸçš„å¸§
        let mid_region_frames: Vec<(usize, &(f64, DynamicImage))> = scene_frames.iter()
            .filter(|(_, (t, _))| *t >= scene_mid_start && *t <= scene_mid_end)
            .cloned()
            .collect();
        
        let keyframe_idx = if mid_region_frames.is_empty() {
            // å¦‚æœä¸­é—´åŒºåŸŸæ²¡æœ‰å¸§ï¼Œé€‰æ‹©åœºæ™¯ä¸­é—´ä½ç½®çš„å¸§
            let target_time = scene_start + duration * 0.5;
            scene_frames.iter()
                .min_by(|(_, (t1, _)), (_, (t2, _))| {
                    ((*t1 - target_time).abs()).partial_cmp(&((*t2 - target_time).abs())).unwrap()
                })
                .map(|(idx, _)| *idx)
                .unwrap_or_else(|| {
                    // å¦‚æœæ‰¾ä¸åˆ°æœ€æ¥è¿‘çš„å¸§ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¸§
                    scene_frames.first()
                        .map(|(idx, _)| *idx)
                        .unwrap_or_else(|| {
                            // å¦‚æœ scene_frames ä¹Ÿä¸ºç©ºï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå…¨å±€å¸§
                            println!("âš ï¸  åœºæ™¯ {}: æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å¸§ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå…¨å±€å¸§", i);
                            0
                        })
                })
        } else if mid_region_frames.len() == 1 {
            // å¦‚æœåªæœ‰ä¸€ä¸ªå¸§ï¼Œç›´æ¥ä½¿ç”¨
            mid_region_frames[0].0
        } else {
            // åœ¨ä¸­é—´åŒºåŸŸé€‰æ‹©æœ€ç¨³å®šçš„å¸§ï¼ˆä¸å‰åå¸§å·®å¼‚æœ€å°ï¼‰
            let mut best_idx = mid_region_frames[0].0;
            let mut min_avg_diff = f64::MAX;
            
            for (frame_idx, (_, _)) in mid_region_frames.iter() {
                let frame_idx_in_all = *frame_idx;
                
                // è®¡ç®—ä¸å‰åå¸§çš„å¹³å‡å·®å¼‚
                let mut diffs = Vec::new();
                
                // ä¸å‰ä¸€ä¸ªå¸§çš„å·®å¼‚
                if frame_idx_in_all > 0 {
                    let prev_frame = &frames[frame_idx_in_all - 1];
                    if prev_frame.0 >= scene_start {
                        let diff = detector.calculate_frame_difference(
                            &prev_frame.1,
                            &frames[frame_idx_in_all].1
                        );
                        diffs.push(diff);
                    }
                }
                
                // ä¸åä¸€ä¸ªå¸§çš„å·®å¼‚
                if frame_idx_in_all + 1 < frames.len() {
                    let next_frame = &frames[frame_idx_in_all + 1];
                    if next_frame.0 < scene_end {
                        let diff = detector.calculate_frame_difference(
                            &frames[frame_idx_in_all].1,
                            &next_frame.1
                        );
                        diffs.push(diff);
                    }
                }
                
                // è®¡ç®—å¹³å‡å·®å¼‚
                let avg_diff = if diffs.is_empty() {
                    f64::MAX
                } else {
                    diffs.iter().sum::<f64>() / diffs.len() as f64
                };
                
                // é€‰æ‹©å·®å¼‚æœ€å°çš„å¸§ï¼ˆæœ€ç¨³å®šçš„å¸§ï¼‰
                if avg_diff < min_avg_diff {
                    min_avg_diff = avg_diff;
                    best_idx = frame_idx_in_all;
                }
            }
            
            best_idx
        };
        
        let (_keyframe_time, keyframe_img) = &frames[keyframe_idx];
        
        // ä¿å­˜å…³é”®å¸§å›¾ç‰‡
        let keyframe_filename = format!("keyframe_{:04}.jpg", keyframe_counter);
        let keyframe_path = output_dir.join(&keyframe_filename);
        keyframe_img.save(&keyframe_path)
            .context(format!("ä¿å­˜å…³é”®å¸§å¤±è´¥: {}", keyframe_filename))?;
        
        keyframe_files.push(keyframe_filename.clone());
        
        // åœºæ™¯å…ƒæ•°æ®
        scenes_metadata.push(crate::metadata::SceneMetadata {
            scene_id: i,
            keyframe_file: keyframe_filename,
            start_time: scene_start,
            end_time: scene_end,
            duration,
        });
        
        keyframe_counter += 1;
    }
    let keyframe_duration = keyframe_start.elapsed();
    println!("[{}ms] âœ“ å…³é”®å¸§æå–å®Œæˆ: {} ä¸ªå…³é”®å¸§ (å¹³å‡ {:.2}ms/å¸§)", 
        keyframe_duration.as_millis(),
        keyframe_files.len(),
        if keyframe_files.len() > 0 { keyframe_duration.as_millis() as f64 / keyframe_files.len() as f64 } else { 0.0 });

    // 6. æå–éŸ³é¢‘
    let audio_start = Instant::now();
    println!("â³ æ­£åœ¨æå–éŸ³é¢‘...");
    let audio_filename = "audio.aac";
    let audio_path = output_dir.join(&audio_filename);
    let audio_extractor = AudioExtractor::new(input_video_path)?;
    audio_extractor.extract_to_file(&audio_path)?;
    let audio_duration = audio_start.elapsed();
    println!("[{}ms] âœ“ éŸ³é¢‘æå–å®Œæˆ: {}", audio_duration.as_millis(), audio_path.display());

    // 7. ç”Ÿæˆå…ƒæ•°æ® JSON
    let metadata_start = Instant::now();
    println!("â³ æ­£åœ¨ç”Ÿæˆå…ƒæ•°æ®...");
    let metadata = VideoMetadata {
        input_video: input_video_path.to_string_lossy().to_string(),
        total_duration,
        fps,
        resolution: format!("{}x{}", width, height),
        scene_count: scenes_metadata.len(),
        audio_file: audio_filename.to_string(),
        scenes: scenes_metadata,
    };
    
    let metadata_path = output_dir.join("metadata.json");
    let metadata_json = serde_json::to_string_pretty(&metadata)
        .context("åºåˆ—åŒ–å…ƒæ•°æ®å¤±è´¥")?;
    std::fs::write(&metadata_path, metadata_json)
        .context("å†™å…¥å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥")?;
    let metadata_duration = metadata_start.elapsed();
    println!("[{}ms] âœ“ å…ƒæ•°æ®ç”Ÿæˆå®Œæˆ: {}", metadata_duration.as_millis(), metadata_path.display());
    
    // æ€»ç»“
    let total_duration = total_start.elapsed();
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ‰ å¤„ç†å®Œæˆï¼æ€»è€—æ—¶: {:.2}ç§’ ({:.0}ms)", 
        total_duration.as_secs_f64(), 
        total_duration.as_millis());
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ“Š æ€§èƒ½ç»Ÿè®¡:");
    println!("   â€¢ è§†é¢‘å¸§æå–: {:.2}ç§’ ({:.1}%)", 
        extract_duration.as_secs_f64(),
        extract_duration.as_secs_f64() / total_duration.as_secs_f64() * 100.0);
    println!("   â€¢ åœºæ™¯æ£€æµ‹: {:.2}ç§’ ({:.1}%)", 
        scene_duration.as_secs_f64(),
        scene_duration.as_secs_f64() / total_duration.as_secs_f64() * 100.0);
    println!("   â€¢ å…³é”®å¸§æå–: {:.2}ç§’ ({:.1}%)", 
        keyframe_duration.as_secs_f64(),
        keyframe_duration.as_secs_f64() / total_duration.as_secs_f64() * 100.0);
    println!("   â€¢ éŸ³é¢‘æå–: {:.2}ç§’ ({:.1}%)", 
        audio_duration.as_secs_f64(),
        audio_duration.as_secs_f64() / total_duration.as_secs_f64() * 100.0);
    println!("   â€¢ å…ƒæ•°æ®ç”Ÿæˆ: {:.2}ç§’ ({:.1}%)", 
        metadata_duration.as_secs_f64(),
        metadata_duration.as_secs_f64() / total_duration.as_secs_f64() * 100.0);
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ“ è¾“å‡ºç›®å½•: {}", output_dir.display());
    println!("ğŸ“¸ å…³é”®å¸§æ•°é‡: {}", metadata.scene_count);
    println!("ğŸµ éŸ³é¢‘æ–‡ä»¶: {}", audio_filename);

    let result = ProcessOutput {
        output_dir: output_dir.to_path_buf(),
        metadata: metadata.clone(),
        keyframe_files: keyframe_files.clone(),
        audio_file: audio_filename.to_string(),
    };

    // è°ƒç”¨ webhook å›è°ƒï¼ˆå¦‚æœé…ç½®äº†ï¼‰
    if let Some(webhook_url) = &config.webhook_url {
        if let Err(e) = call_webhook(webhook_url, &result, &metadata).await {
            tracing::warn!("Webhook å›è°ƒå¤±è´¥: {}", e);
        } else {
            println!("âœ“ Webhook å›è°ƒæˆåŠŸ");
        }
    }

    Ok(result)
}

/// Webhook å›è°ƒæ•°æ®ç»“æ„
#[derive(Debug, serde::Serialize)]
struct WebhookPayload {
    /// å¤„ç†çŠ¶æ€
    status: String,
    /// è¾“å…¥è§†é¢‘è·¯å¾„
    input_video: String,
    /// è¾“å‡ºç›®å½•
    output_dir: String,
    /// åœºæ™¯æ•°é‡
    scene_count: usize,
    /// å…³é”®å¸§æ•°é‡
    keyframe_count: usize,
    /// éŸ³é¢‘æ–‡ä»¶
    audio_file: String,
    /// è§†é¢‘å…ƒæ•°æ®
    metadata: VideoMetadata,
    /// å¤„ç†æ—¶é—´æˆ³
    timestamp: String,
}

/// è°ƒç”¨ webhook å›è°ƒ
async fn call_webhook(
    webhook_url: &str,
    result: &ProcessOutput,
    metadata: &VideoMetadata,
) -> Result<()> {
    use chrono::Utc;

    let timestamp = Utc::now().to_rfc3339();

    let payload = WebhookPayload {
        status: "success".to_string(),
        input_video: metadata.input_video.clone(),
        output_dir: result.output_dir.to_string_lossy().to_string(),
        scene_count: metadata.scene_count,
        keyframe_count: result.keyframe_files.len(),
        audio_file: result.audio_file.clone(),
        metadata: metadata.clone(),
        timestamp,
    };

    let client = reqwest::Client::new();
    let response = client
        .post(webhook_url)
        .json(&payload)
        .timeout(std::time::Duration::from_secs(30))
        .send()
        .await
        .context("Webhook è¯·æ±‚å¤±è´¥")?;

    let status = response.status();
    if status.is_success() {
        tracing::info!("Webhook å›è°ƒæˆåŠŸ: {}", webhook_url);
    } else {
        let error_text = response.text().await.unwrap_or_default();
        tracing::warn!(
            "Webhook å›è°ƒè¿”å›é”™è¯¯çŠ¶æ€: {} - {}",
            status,
            error_text
        );
        return Err(anyhow::anyhow!(
            "Webhook è¿”å›é”™è¯¯çŠ¶æ€: {}",
            status
        ));
    }

    Ok(())
}