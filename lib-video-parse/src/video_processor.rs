use ffmpeg_next as ffmpeg;
use image::DynamicImage;
use anyhow::{Context, Result};
use std::path::Path;
use std::time::Instant;
use std::io::{self, Write};

/// è§†é¢‘å¤„ç†å™¨ï¼Œè´Ÿè´£è§£ç è§†é¢‘å¹¶æå–å¸§
pub struct VideoProcessor {
    input_path: String,
}

impl VideoProcessor {
    pub fn new(input_path: impl AsRef<Path>) -> Result<Self> {
        ffmpeg::init().context("åˆå§‹åŒ– FFmpeg å¤±è´¥")?;
        
        // è®¾ç½® FFmpeg æ—¥å¿—çº§åˆ«ä¸º ERRORï¼ŒæŠ‘åˆ¶è­¦å‘Šå’Œä¿¡æ¯æ¶ˆæ¯
        // æ—¥å¿—çº§åˆ«ï¼španic, fatal, error, warning, info, verbose, debug, trace
        // è®¾ç½®ä¸º error çº§åˆ«ï¼Œåªæ˜¾ç¤ºé”™è¯¯å’Œè‡´å‘½é”™è¯¯
        unsafe {
            ffmpeg::sys::av_log_set_level(ffmpeg::sys::AV_LOG_ERROR as i32);
        }
        
        Ok(Self {
            input_path: input_path.as_ref().to_string_lossy().to_string(),
        })
    }

    /// è·å–è§†é¢‘ä¿¡æ¯
    pub fn get_video_info(&self) -> Result<(f64, u32, u32)> {
        let ictx = ffmpeg::format::input(&self.input_path)
            .context("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")?;
        
        let video_stream = ictx
            .streams()
            .best(ffmpeg::media::Type::Video)
            .context("æœªæ‰¾åˆ°è§†é¢‘æµ")?;
        
        let decoder_context = ffmpeg::codec::context::Context::from_parameters(video_stream.parameters())
            .context("æ— æ³•åˆ›å»ºè§£ç å™¨ä¸Šä¸‹æ–‡")?;
        
        let decoder = decoder_context.decoder()
            .video()
            .context("æ— æ³•åˆ›å»ºè§†é¢‘è§£ç å™¨")?;
        
        let fps = video_stream.avg_frame_rate();
        let fps_value = if fps.denominator() > 0 {
            fps.numerator() as f64 / fps.denominator() as f64
        } else {
            30.0 // é»˜è®¤å€¼
        };
        
        Ok((fps_value, decoder.width(), decoder.height()))
    }

    /// æå–è§†é¢‘å¸§ï¼ˆä¼˜åŒ–ç‰ˆï¼šä½¿ç”¨ seek è·³è½¬ï¼Œå¤§å¹…åŠ é€Ÿï¼‰
    /// è¿”å› (æ—¶é—´æˆ³(ç§’), å›¾åƒ) çš„å‘é‡
    pub fn extract_frames(&self, sample_rate: Option<f64>) -> Result<Vec<(f64, DynamicImage)>> {
        // å…ˆè·å–è§†é¢‘ä¿¡æ¯
        let (fps_value, _width, _height) = self.get_video_info()?;
        
        // æ‰“å¼€è§†é¢‘æ–‡ä»¶
        let mut ictx = ffmpeg::format::input(&self.input_path)
            .context("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")?;
        
        let video_stream_index = ictx
            .streams()
            .best(ffmpeg::media::Type::Video)
            .context("æœªæ‰¾åˆ°è§†é¢‘æµ")?
            .index();
        
        // ä¿å­˜ video_stream_index å’Œ time_baseï¼Œé¿å…å€Ÿç”¨é—®é¢˜
        let time_base = ictx.stream(video_stream_index).unwrap().time_base();
        
        // è·å–è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        let duration = ictx.duration() as f64 / ffmpeg::ffi::AV_TIME_BASE as f64;
        
        // é‡‡æ ·ç‡ï¼šå¦‚æœæŒ‡å®šäº†ï¼Œä½¿ç”¨æŒ‡å®šçš„ï¼›å¦åˆ™ä½¿ç”¨ fps
        let sample_rate = sample_rate.unwrap_or(fps_value);
        
        // è®¡ç®—éœ€è¦æå–çš„æ—¶é—´ç‚¹
        let frame_interval = 1.0 / sample_rate; // æ¯å¸§ä¹‹é—´çš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
        let num_frames = (duration / frame_interval).ceil() as usize;
        
        // åˆ›å»ºè§£ç å™¨ä¸Šä¸‹æ–‡çš„è¾…åŠ©å‡½æ•°ï¼ˆé¿å…é‡å¤ä»£ç ï¼‰
        let create_decoder_context = || -> Result<ffmpeg::codec::context::Context> {
            Ok(ffmpeg::codec::context::Context::from_parameters(
                ictx.stream(video_stream_index).unwrap().parameters()
            ).context("æ— æ³•åˆ›å»ºè§£ç å™¨ä¸Šä¸‹æ–‡")?)
        };
        
        let decoder_context = create_decoder_context()?;
        
        // ç¦ç”¨ç¡¬ä»¶åŠ é€Ÿï¼Œç›´æ¥ä½¿ç”¨è½¯ä»¶è§£ç 
        // ç¡¬ä»¶åŠ é€Ÿåœ¨æŸäº›æƒ…å†µä¸‹ä¸ç¨³å®šï¼Œç‰¹åˆ«æ˜¯ä½¿ç”¨ seek çš„åœºæ™¯
        
        let mut decoder = decoder_context.decoder()
            .video()
            .context("æ— æ³•åˆ›å»ºè§†é¢‘è§£ç å™¨")?;
        
        // åˆ›å»ºç¼©æ”¾å™¨ï¼ˆè½¯ä»¶è§£ç ï¼‰
        let input_format = decoder.format();
        
        let mut scaler = ffmpeg::software::scaling::Context::get(
            input_format,
            decoder.width(),
            decoder.height(),
            ffmpeg::format::Pixel::RGB24,
            decoder.width(),
            decoder.height(),
            ffmpeg::software::scaling::Flags::BILINEAR,
        ).context("æ— æ³•åˆ›å»ºç¼©æ”¾å™¨")?;
        
        let mut frames = Vec::new();
        
        // è¿›åº¦è·Ÿè¸ª
        let extract_start_time = Instant::now();
        let progress_interval = (num_frames / 20).max(1); // æ¯5%æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦æ¡
        let log_interval = (num_frames / 10).max(1); // æ¯10%è¾“å‡ºä¸€æ¬¡è¯¦ç»†æ—¥å¿—
        let mut last_log_time = Instant::now();
        let mut last_log_frame = 0;
        
        println!("   ğŸ“Š å¸§æå–å‚æ•°:");
        println!("      â€¢ é¢„è®¡æå–å¸§æ•°: {} å¸§", num_frames);
        println!("      â€¢ è§†é¢‘æ—¶é•¿: {:.2}ç§’", duration);
        println!("      â€¢ é‡‡æ ·é—´éš”: {:.3}ç§’", frame_interval);
        println!("   ğŸš€ å¼€å§‹æå–è§†é¢‘å¸§...");
        
        // å¯¹æ¯ä¸ªéœ€è¦æå–çš„æ—¶é—´ç‚¹è¿›è¡Œ seek å’Œè§£ç 
        for i in 0..num_frames {
            let target_time = i as f64 * frame_interval;
            
            // å¦‚æœè¶…è¿‡è§†é¢‘æ—¶é•¿ï¼Œåœæ­¢
            if target_time >= duration {
                break;
            }
            
            // å°†æ—¶é—´è½¬æ¢ä¸ºæ—¶é—´æˆ³ï¼ˆåŸºäº AV_TIME_BASEï¼‰
            let timestamp = (target_time * ffmpeg::ffi::AV_TIME_BASE as f64) as i64;
            
            // Seek åˆ°ç›®æ ‡æ—¶é—´ç‚¹ï¼ˆå‘åæŸ¥æ‰¾æœ€è¿‘çš„ keyframeï¼‰
            unsafe {
                let ret = ffmpeg::sys::av_seek_frame(
                    ictx.as_mut_ptr(),
                    -1, // å¯¹æ‰€æœ‰æµ seek
                    timestamp,
                    ffmpeg::sys::AVSEEK_FLAG_BACKWARD as i32, // å‘åæŸ¥æ‰¾æœ€è¿‘çš„ keyframe
                );
                if ret < 0 {
                    // Seek å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªæ—¶é—´ç‚¹
                    continue;
                }
            }
            
            // åˆ·æ–°è§£ç å™¨ç¼“å†²åŒº
            decoder.flush();
            
            // è¯»å–å¹¶è§£ç å¸§ï¼Œç›´åˆ°æ‰¾åˆ°ç›®æ ‡æ—¶é—´ç‚¹é™„è¿‘çš„å¸§
            let mut found_frame = false;
            let mut best_frame: Option<(f64, DynamicImage)> = None;
            let mut best_time_diff = f64::MAX;
            
            // è¯»å–ä¸€äº›æ•°æ®åŒ…æ¥æ‰¾åˆ°æœ€æ¥è¿‘ç›®æ ‡æ—¶é—´çš„å¸§
            let mut packets_read = 0;
            const MAX_PACKETS_TO_READ: usize = 50; // æœ€å¤šè¯»å–50ä¸ªæ•°æ®åŒ…æ¥æ‰¾åˆ°ç›®æ ‡å¸§
            
            for (stream, packet) in ictx.packets() {
                if stream.index() != video_stream_index {
                    continue;
                }
                
                packets_read += 1;
                if packets_read > MAX_PACKETS_TO_READ {
                    break; // é¿å…æ— é™å¾ªç¯
                }
                
                let send_result = decoder.send_packet(&packet);
                if send_result.is_err() {
                    // å‘é€æ•°æ®åŒ…å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªæ•°æ®åŒ…
                    continue;
                }
                
                let mut decoded = ffmpeg::frame::Video::empty();
                
                while decoder.receive_frame(&mut decoded).is_ok() {
                    let frame_time = decoded.timestamp()
                        .map(|ts| {
                            let tb_num = time_base.numerator() as f64;
                            let tb_den = time_base.denominator() as f64;
                            ts as f64 * tb_num / tb_den
                        })
                        .unwrap_or(0.0);
                    
                    let time_diff = (frame_time - target_time).abs();
                    
                    // å¦‚æœæ‰¾åˆ°æ›´æ¥è¿‘ç›®æ ‡æ—¶é—´çš„å¸§ï¼Œä¿å­˜å®ƒ
                    if time_diff < best_time_diff {
                        best_time_diff = time_diff;
                        
                        // å¦‚æœæ—¶é—´å·®å°äºä¸€ä¸ªé‡‡æ ·é—´éš”çš„ä¸€åŠï¼Œè®¤ä¸ºæ‰¾åˆ°äº†åˆé€‚çš„å¸§
                        if time_diff <= frame_interval / 2.0 {
                            // è§£ç å¹¶è½¬æ¢å¸§ï¼ˆè½¯ä»¶è§£ç ï¼‰
                            let mut rgb_frame = ffmpeg::frame::Video::empty();
                            if scaler.run(&decoded, &mut rgb_frame).is_ok() {
                                if let Ok(img) = self.frame_to_image(&rgb_frame) {
                                    best_frame = Some((frame_time, img));
                                    found_frame = true;
                                }
                            }
                        }
                    }
                    
                    // å¦‚æœå·²ç»è¶…è¿‡ç›®æ ‡æ—¶é—´å¤ªå¤šï¼Œåœæ­¢æœç´¢
                    if frame_time > target_time + frame_interval {
                        break;
                    }
                }
                
                // å¦‚æœæ‰¾åˆ°äº†åˆé€‚çš„å¸§ï¼Œåœæ­¢è¯»å–æ›´å¤šæ•°æ®åŒ…
                if found_frame {
                    break;
                }
            }
            
            // å¦‚æœæ‰¾åˆ°äº†å¸§ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
            if let Some((time, img)) = best_frame {
                frames.push((time, img));
            }
            
            // æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆæ¯5%æ›´æ–°ä¸€æ¬¡ï¼‰
            if (i + 1) % progress_interval == 0 || i == num_frames - 1 {
                let progress = ((i + 1) as f64 / num_frames as f64 * 100.0) as u32;
                let elapsed = extract_start_time.elapsed();
                let elapsed_secs = elapsed.as_secs_f64();
                let fps = (i + 1) as f64 / elapsed_secs.max(0.001);
                let remaining_frames = num_frames - (i + 1);
                let estimated_remaining = if fps > 0.0 {
                    remaining_frames as f64 / fps
                } else {
                    0.0
                };
                
                // è®¡ç®—è¿›åº¦æ¡
                let bar_width = 30;
                let filled = (progress as f64 / 100.0 * bar_width as f64) as usize;
                let bar = "â–ˆ".repeat(filled) + &"â–‘".repeat(bar_width - filled);
                
                print!("\r   ğŸ“ˆ è¿›åº¦: [{}] {}% ({}/{}) | å·²ç”¨: {:.1}s | é€Ÿåº¦: {:.1} å¸§/s | å‰©ä½™: {:.1}s     ", 
                    bar, progress, i + 1, num_frames, elapsed_secs, fps, estimated_remaining);
                io::stdout().flush().ok();
            }
            
            // è¾“å‡ºè¯¦ç»†æ—¥å¿—ï¼ˆæ¯10%è¾“å‡ºä¸€æ¬¡ï¼‰
            if (i + 1) % log_interval == 0 || i == num_frames - 1 {
                let progress = ((i + 1) as f64 / num_frames as f64 * 100.0) as u32;
                let elapsed = extract_start_time.elapsed();
                let elapsed_secs = elapsed.as_secs_f64();
                let avg_fps = (i + 1) as f64 / elapsed_secs.max(0.001);
                
                // è®¡ç®—æœ€è¿‘ä¸€æ®µæ—¶é—´çš„é€Ÿåº¦
                let frames_since_last_log = (i + 1) - last_log_frame;
                let time_since_last_log = last_log_time.elapsed().as_secs_f64();
                let recent_fps = if time_since_last_log > 0.0 && frames_since_last_log > 0 {
                    frames_since_last_log as f64 / time_since_last_log
                } else {
                    avg_fps
                };
                
                // è¾“å‡ºè¯¦ç»†æ—¥å¿—ï¼ˆæ¢è¡Œè¾“å‡ºï¼Œä¸å½±å“è¿›åº¦æ¡ï¼‰
                println!("\n   ğŸ“ è¿›åº¦æ—¥å¿—: {}% ({}/{}) | å·²ç”¨: {:.1}s | å¹³å‡é€Ÿåº¦: {:.1} å¸§/s | å½“å‰é€Ÿåº¦: {:.1} å¸§/s", 
                    progress, i + 1, num_frames, elapsed_secs, avg_fps, recent_fps);
                
                last_log_frame = i + 1;
                last_log_time = Instant::now();
            }
        }
        
        println!(); // æ¢è¡Œï¼Œç»“æŸè¿›åº¦æ˜¾ç¤º
        
        // è¾“å‡ºæå–å®Œæˆæ€»ç»“
        let total_elapsed = extract_start_time.elapsed();
        let total_secs = total_elapsed.as_secs_f64();
        let avg_fps = frames.len() as f64 / total_secs.max(0.001);
        println!("   âœ… å¸§æå–å®Œæˆ!");
        println!("      â€¢ æˆåŠŸæå–: {} å¸§", frames.len());
        println!("      â€¢ æ€»è€—æ—¶: {:.2}ç§’ ({:.0}ms)", total_secs, total_elapsed.as_millis());
        println!("      â€¢ å¹³å‡é€Ÿåº¦: {:.2} å¸§/ç§’", avg_fps);
        println!("      â€¢ å¹³å‡è€—æ—¶: {:.2}ms/å¸§", total_elapsed.as_millis() as f64 / frames.len().max(1) as f64);
        
        Ok(frames)
    }

    /// å°† FFmpeg å¸§è½¬æ¢ä¸º DynamicImage
    fn frame_to_image(&self, frame: &ffmpeg::frame::Video) -> Result<DynamicImage> {
        let width = frame.width();
        let height = frame.height();
        let data = frame.data(0);
        
        // RGB24 æ ¼å¼ï¼šæ¯ä¸ªåƒç´  3 å­—èŠ‚
        let mut img_buf = image::RgbImage::new(width, height);
        
        for y in 0..height {
            for x in 0..width {
                let idx = ((y * frame.stride(0) as u32) + (x * 3)) as usize;
                if idx + 2 < data.len() {
                    let r = data[idx];
                    let g = data[idx + 1];
                    let b = data[idx + 2];
                    img_buf.put_pixel(x, y, image::Rgb([r, g, b]));
                }
            }
        }
        
        Ok(DynamicImage::ImageRgb8(img_buf))
    }
    
}